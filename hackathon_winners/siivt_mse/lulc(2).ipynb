{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ec5e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a6999891f224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import concatenate\n",
    "import tensorflow.keras as tfk\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, cohen_kappa_score\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "import timeit\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "from sklearn.utils.extmath import softmax\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import geopandas as gpd\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to download images from the provided date range\n",
    "def download_images(start_date, end_date):\n",
    "    setup_logging(1)  # 0: nothing, 1: only progress bars, 2: INFO, 3: DEBUG\n",
    "\n",
    "    dag = EODataAccessGateway()\n",
    "    geometry = \"POLYGON ((8.657227 36.958086, 8.97583 37.001968, 8.986816 36.729493, 9.085693 36.491385, 8.789063 36.411852, 8.371582 36.385323, 8.129883 36.464883, 8.360596 36.579658, 8.415527 36.755904, 8.613281 36.843875, 8.657227 36.958086))\"\n",
    "    search_results, total_count = dag.search(\n",
    "        productType=\"S2_MSI_L1C\",\n",
    "        geom=geometry,\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        cloudCover=4,\n",
    "    )\n",
    "\n",
    "    products_to_download = search_results[:2]  # Download 2 images, change as needed\n",
    "    paths = dag.download_all(products_to_download)\n",
    "    for file_path in paths:\n",
    "        destination_path = os.path.join(\n",
    "            \"sentinel2\", os.path.basename(file_path)\n",
    "        )\n",
    "        shutil.move(file_path, destination_path)\n",
    "\n",
    "# Download images for the specified date ranges\n",
    "date_ranges = [\n",
    "    (\"2022-01-20\", \"2022-02-23\"),\n",
    "    (\"2023-11-13\", \"2023-11-15\")\n",
    "]\n",
    "\n",
    "for start_date, end_date in date_ranges:\n",
    "    download_images(start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18916d41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_paths = [\n",
    "    ('sentinel2/T32SMF_20231114T101159_B02.jp2',\n",
    "     'sentinel2/T32SMF_20231114T101159_B03.jp2'),\n",
    "    ('sentinel2/T32SMF_20231114T101159_B04.jp2',\n",
    "     'sentinel2/T32SMF_20231114T101159_B08.jp2')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0285c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########## Read Bands for pixel based classification\n",
    "b2 = rasterio.open('sentinel2/T32SMF_20231114T101159_B02.jp2')\n",
    "b2_array = b2.read()\n",
    "b2_array = np.moveaxis(b2_array,0,-1)\n",
    "b2_array = (b2_array - np.percentile(b2_array, 2) )/ (np.percentile(b2_array, 98) - np.percentile(b2_array, 2) )\n",
    "\n",
    "\n",
    "b3 = rasterio.open('sentinel2/T32SMF_20231114T101159_B03.jp2')\n",
    "b3_array = b3.read()\n",
    "b3_array = np.moveaxis(b3_array,0,-1)\n",
    "b3_array = (b3_array - np.percentile(b3_array, 2) )/ (np.percentile(b3_array, 98) - np.percentile(b3_array, 2) )\n",
    "\n",
    "\n",
    "b4 = rasterio.open('sentinel2/T32SMF_20231114T101159_B04.jp2')\n",
    "b4_array = b4.read()\n",
    "b4_array = np.moveaxis(b4_array,0,-1)\n",
    "b4_array = (b4_array - np.percentile(b4_array, 2) )/ (np.percentile(b4_array, 98) - np.percentile(b4_array, 2) )\n",
    "\n",
    "\n",
    "b8 = rasterio.open('sentinel2/T32SMF_20231114T101159_B08.jp2')\n",
    "b8_array = b8.read()\n",
    "b8_array = np.moveaxis(b8_array,0,-1)\n",
    "b8_array = (b8_array - np.percentile(b8_array, 2) )/ (np.percentile(b8_array, 98) - np.percentile(b8_array, 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd969a82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store time series data\n",
    "time_series_data = []\n",
    "\n",
    "# Loop through each date\n",
    "for date_images in image_paths:\n",
    "    # Initialize an empty list to store band data for the current date\n",
    "    date_data = []\n",
    "    \n",
    "    # Loop through each band for the current date\n",
    "    for band_path in date_images:\n",
    "        # Read band data using rasterio\n",
    "        with rasterio.open(band_path) as src:\n",
    "            band_data = src.read(1)  # Read band data (adjust band index if needed)\n",
    "            date_data.append(band_data)  # Append band data for the current date\n",
    "        \n",
    "    # Stack the bands for the current date into a 3D array\n",
    "    date_array = np.stack(date_data, axis=-1)\n",
    "    \n",
    "    # Append the 3D array representing the bands for the current date to the time series data list\n",
    "    time_series_data.append(date_array)\n",
    "\n",
    "# Stack the 3D arrays for each date into a 4D array representing the entire time series\n",
    "time_series = np.stack(time_series_data, axis=1)\n",
    "time_series = time_series.transpose(0, 2, 1, 3).reshape(10980, 10980, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61fe75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa09f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Lire le fichier de formes\n",
    "shapefile_path = 'Jendouba2.shp'\n",
    "data = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Récupérer les géométries des classes\n",
    "geometries = data['geometry']\n",
    "\n",
    "# Ouvrir la bande b8 avec rasterio\n",
    "with rasterio.open('sentinel2/T32SMF_20231114T101159_B08.jp2') as src:\n",
    "    # Récupérer les dimensions de l'image\n",
    "    largeur_de_l_image = src.width\n",
    "    hauteur_de_l_image = src.height\n",
    "    \n",
    "# Parcourir les pixels de l'image\n",
    "for x in range(largeur_de_l_image):\n",
    "    for y in range(hauteur_de_l_image):\n",
    "        # Coordonnées spatiales du pixel\n",
    "        pixel_coords = Point(x, y)\n",
    "        \n",
    "        # Vérifier si le pixel appartient à l'un des polygones\n",
    "        for idx, geometry in enumerate(geometries):\n",
    "            if geometry.contains(pixel_coords):\n",
    "                # Assigner la classe correspondante au pixel\n",
    "                pixel_class = data['class'][idx]  # 'class' est la colonne des classes dans le shapefile\n",
    "                # Faire quelque chose avec la classe attribuée au pixel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(largeur_de_l_image):\n",
    "    for y in range(hauteur_de_l_image):\n",
    "        # Coordonnées spatiales du pixel\n",
    "        pixel_coords = Point(x, y)\n",
    "        pixel_class = None  # Classe par défaut si le pixel ne correspond à aucun polygone\n",
    "        \n",
    "        # Vérifier si le pixel appartient à l'un des polygones\n",
    "        for idx, geometry in enumerate(geometries):\n",
    "            if geometry.contains(pixel_coords):\n",
    "                # Assigner la classe correspondante au pixel\n",
    "                pixel_class = data['class'][idx]  # 'class' est la colonne des classes dans le shapefile\n",
    "                break  # Sortir de la boucle une fois la classe trouvée\n",
    "        \n",
    "        # Stocker la classe attribuée à ce pixel dans le dictionnaire\n",
    "        class_assignments[(x, y)] = pixel_class\n",
    "\n",
    "# Enregistrer les résultats dans un fichier CSV ou JSON\n",
    "import pandas as pd\n",
    "\n",
    "# Créer un DataFrame à partir du dictionnaire des classes attribuées aux pixels\n",
    "df = pd.DataFrame(list(class_assignments.items()), columns=['Pixel_coords', 'Class'])\n",
    "csv_filename = 'pixel_class_assignments.csv'\n",
    "df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2836e6",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241daa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixels\n",
    "    train_X = []\n",
    "    for band in [b2_array,b3_array,b4_array,b8_array]:\n",
    "        train_X.append( band[train_idx] )\n",
    "        X_train = np.stack(train_X,axis=-1)\n",
    "\n",
    "    valid_X_pxl = []\n",
    "    for band in [b2_array,b3_array,b4_array,b8_array]:\n",
    "        valid_X.append( band[valid_idx] )\n",
    "        X_valid = np.stack(valid_X,axis=-1)\n",
    "\n",
    "    test_X_pxl = []\n",
    "    for band in [b2_array,b3_array,b4_array,b8_array]:\n",
    "        test_X.append( band[test_idx] )\n",
    "        X_test = np.stack(test_X,axis=-1)\n",
    "\n",
    "    np.save('train.npy',X_train)\n",
    "    np.save('test.npy',X_valid)\n",
    "    np.save('valid',X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d5a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_one_branch_model(input_shape, nb_classes):\n",
    "    n_feature_maps = 128\n",
    "    dropOut = 0.5\n",
    "\n",
    "    input_layer = tfk.layers.Input(name=\"input\", shape=input_shape)\n",
    "    # features = getBranch(input_layer, n_feature_maps, dropOut, \"input\")\n",
    "    # dense_layer = tfk.layers.Dense(512, activation='relu')(features)\n",
    "\n",
    "    dense_layer = tfk.layers.Dense(n_feature_maps, activation='relu')(input_layer)\n",
    "    dense_layer = tfk.layers.Dropout(rate=dropOut)(dense_layer)\n",
    "    dense_layer = tfk.layers.Dense(n_feature_maps, activation='relu')(dense_layer)\n",
    "    output_layer = tfk.layers.Dense(nb_classes, activation='softmax')(dense_layer)\n",
    "\n",
    "    model = tfk.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(train_y))\n",
    "model = build_one_branch_model((32), n_classes )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ae84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_X, train_y, epochs=num_epochs, batch_size=batch_size, validation_data=(val_X, val_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e62d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred = model.predict(valid_X_pxl,batch_size=BATCH_SIZE)\n",
    "valid_pred = np.argmax(valid_pred,axis=1)\n",
    "f1_score(valid_y_enc,valid_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11554a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_X_pxl,batch_size=BATCH_SIZE)\n",
    "test_pred = encoder.inverse_transform( np.argmax(test_pred,axis=1) )\n",
    "\n",
    "print ('Acc:',accuracy_score(test_y,test_pred))\n",
    "print ('F1:',f1_score(test_y,test_pred,average='weighted'))\n",
    "print ('F1:',f1_score(test_y,test_pred,average=None))\n",
    "print ('Kappa:',cohen_kappa_score(test_y,test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
